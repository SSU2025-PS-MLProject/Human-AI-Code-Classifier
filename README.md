# Human‑AI Code Classifier

Detects whether a code snippet is written by a human or generated by a Large Language Model (LLM).

## ⚙️ Environment
Python 3.10  
Ubuntu 24.04.2 LTS  
All required dependencies are listed in classifier_env.yaml

## Project Structure
```text
.
├── README.md
├── classifier_env.yaml
├── dataset
│   ├── README.md
│   ├── csv
│   │   ├── cpp_dataset.csv
│   │   ├── python_dataset.csv
│   │   └── sample250_problem_list.csv
│   ├── data_extraction.ipynb
│   ├── description_move.ipynb
│   ├── problem_selection.ipynb
│   └── utils
│       ├── ai_code_generator.py
│       ├── ai_dataset_csv.py
│       ├── code_feature_generator.py
│       ├── merge_csv.py
│       └── python_feature_extractor.py
├── models
│   ├── python_xgb_top2.joblib // XGBoost Python Multilabel classifier
│   ├── svm_python_bin.joblib // SVM Python Binary classifier
│   ├── cpp_xgb_top2.joblib // XGBoost CPP Multilabel classifier
│   └── svm_binary_cpp.joblib // SVM CPP Binary classifier
├── service
│   ├── cpp_utils.py
│   ├── main.py
│   ├── python_utils.py
│   └── static
│       ├── favicon.ico
│       ├── favicon.png
│       └── index.html
└── train
    ├── XGBoost_top2.ipynb
    ├── ensemble_cpp.ipynb
    ├── ensemble_python.ipynb
    └── random_forest.ipynb
```

## 📊 Dataset
Dataset directory: dataset/csv/final  
Total samples:  
2,500 human-written code samples  
2,500 LLM-generated code samples from (500 samples each): 
- GPT-4.1-mini
- GROK3
- Mistral-code
- DeepSeek V3
- Gemini 2.5 Flash

## 🧠 Training

Training code and Jupyter notebooks are available in the train/ directory.
Models include:  
- SVM
- XGBoost
- Random Forest
- Ensemble (major voting)

## 🛠️ Setup

### 1. Install Miniconda (skip if already installed)

```
curl -L -O "https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-$(uname)-$(uname -m).sh"
bash Miniforge3-$(uname)-$(uname -m).sh
```

### 2. Clone the repository

```
git clone https://github.com/SSU2025-PS-MLProject/human-ai-code-classifier.git
cd Human-AI-Code-Classifier
```

### 3. Set up the Conda environment

```
conda env create -f classifier_env.yaml
conda activate classifier
```

### 4. Set up environment variables (for C++ feature extraction)

After setting up the environment, locate the libclang.so file and export it:

#### Find the path
```
conda env list          # find your env path
find [ENV_PATH] -name "libclang.so*" 2>/dev/null
```

#### Export the path
```
export CLANG_LIBRARY_FILE=/your/path/to/libclang.so
```

### 5. Download pretrained models
LINK : https://drive.google.com/drive/folders/1R4OHNtSXkwGv0OZfbJ79RSYsXGIIJ0Sn?usp=sharing  
Download pretrained models from Google Drive and place them in the following directory structure:
```
project-root/
└─ models/
   ├─ ensemble_cpp_binary.joblib
   ├─ ensemble_cpp_multi.joblib
   ├─ ensemble_python_binary.joblib
   └─ ensemble_python_multi.joblib
```
Note: The API loads models from ../models/. Adjust the path if needed.

⸻

## 🚀 Running the Web/API Server

```
cd service
uvicorn main:app --host 0.0.0.0 --port [AnyPort] --reload
```
`--reload` argument is optional

You can add `--workers [numberOfProcess]` argument if you want to process multiple requests

## Web page
You can access web page at: http://[YourPublicIpAddr]:[Port]

## 🔍 Swagger Documentation

Access the API docs at: http://[YourPublicIpAddr]:[Port]/docs

## 📝 Notes
This server is intended for local or single-user testing.  
For multi-user support or deployment, consider containerizing the service or modifying main.py accordingly.  
