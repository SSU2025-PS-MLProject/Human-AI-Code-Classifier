{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57ca97a2-773d-4da1-b3a5-639cee16380e",
   "metadata": {},
   "source": [
    "# 모델 학습에 필요한 함수 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49efb4b0-33e3-4b90-92c9-c7d3f06719f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, GroupShuffleSplit\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9499130-75f7-4ad2-918a-7069dd40369c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 개수에 맞춰 train_test_split\n",
    "def extraction_multiclass_version1(df, features_list, model_column_name='model', original_label_column_name='label'):\n",
    "    \n",
    "    # 1. 고유한 모델 식별자 생성 (예: \"0_모델A\", \"1_모델B\")\n",
    "    df['multiclass_target_str'] = df[original_label_column_name].astype(str) + '_' + df[model_column_name].astype(str)\n",
    "\n",
    "    # 2. LabelEncoder를 사용하여 문자열 타겟을 정수형으로 변환 (0, 1, 2, 3, 4, 5)\n",
    "    encoder = LabelEncoder()\n",
    "    df['multiclass_target_encoded'] = encoder.fit_transform(df['multiclass_target_str'])\n",
    "\n",
    "    # 생성된 고유 클래스 확인 (디버깅용)\n",
    "    print(\"생성된 고유 클래스 (문자열):\", encoder.classes_)\n",
    "    print(\"인코딩된 클래스 수:\", len(encoder.classes_))\n",
    "\n",
    "    X = df[features_list]\n",
    "    y = df['multiclass_target_encoded'] # 새로 인코딩된 다중 클래스 타겟\n",
    "\n",
    "    # 다중 클래스 타겟을 기준으로 계층적 샘플링 수행\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # encoder.classes_는 나중에 예측 결과를 원래 모델명으로 해석할 때 유용합니다.\n",
    "    return X_train, X_test, y_train, y_test, encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7f48ace-1895-4081-b445-0b83bad4a725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문제, 모델 개수에 맞춰 train_test_split\n",
    "def extraction_multiclass_version2(df, feature_cols, target_col_1, target_col_2, group_col, test_size=0.2, random_state=42):\n",
    "    df_processed = df.copy()\n",
    "\n",
    "    # 1. 다중 클래스 타겟 생성\n",
    "    df_processed['multiclass_target_str'] = df_processed[target_col_1].astype(str) + '_' + df_processed[target_col_2].astype(str)\n",
    "    encoder = LabelEncoder()\n",
    "    df_processed['multiclass_target_encoded'] = encoder.fit_transform(df_processed['multiclass_target_str'])\n",
    "    class_names = encoder.classes_\n",
    "    \n",
    "    X = df_processed[feature_cols]\n",
    "    y = df_processed['multiclass_target_encoded']\n",
    "    groups = df_processed[group_col]\n",
    "\n",
    "    splitter = GroupShuffleSplit(test_size=test_size, n_splits=1, random_state=random_state)\n",
    "    train_idx, test_idx = next(splitter.split(X, y, groups=groups))\n",
    "\n",
    "    X_train = X.iloc[train_idx]\n",
    "    y_train = y.iloc[train_idx]\n",
    "    X_test = X.iloc[test_idx]\n",
    "    y_test = y.iloc[test_idx]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, encoder, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6500fe3-fdc4-4ba8-b532-e7b7a321a7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_with_best_params(X_train, X_test, y_train, y_test, num_classes, best_params, class_names=None):\n",
    "    xgb_params = {key.replace('tree__', ''): value for key, value in best_params.items()}\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        (\"sc\", StandardScaler()),\n",
    "        (\"tree\", XGBClassifier(\n",
    "            objective='multi:softmax',   # 다중 분류\n",
    "            num_class=num_classes,       # 클래스 개수 명시\n",
    "            eval_metric='mlogloss',      # 다중 분류용 logloss\n",
    "            random_state=42,\n",
    "            use_label_encoder=False,     # 최신 XGBoost 권장\n",
    "            **xgb_params                 # 최적 하이퍼파라미터 적용\n",
    "        )),\n",
    "    ])\n",
    "\n",
    "    print(\"🚀 모델 학습 시작 (최적 파라미터 사용)...\")\n",
    "    pipe.fit(X_train, y_train)\n",
    "    print(\"✅ 모델 학습 완료!\")\n",
    "\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    y_pred_proba = pipe.predict_proba(X_test) # 확률값 (필요시 사용)\n",
    "\n",
    "    print(\"\\n--- 테스트 결과 ---\")\n",
    "    print(\"✅ Test Classification Report:\")\n",
    "    if class_names is not None:\n",
    "        unique_labels_in_data = sorted(list(pd.unique(y_test))) # 실제 데이터의 레이블 확인\n",
    "        report_class_names = [str(class_names[i]) for i in unique_labels_in_data if i < len(class_names)]\n",
    "\n",
    "        print(classification_report(y_test, y_pred, target_names=report_class_names, labels=unique_labels_in_data))\n",
    "    else:\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # f1_score 함수에도 average 방식 지정\n",
    "    final_f1_score = f1_score(y_test, y_pred, average='macro')\n",
    "    print(f\"✅ Test F1 Macro Score: {final_f1_score:.3f}\")\n",
    "\n",
    "    # 특성 중요도 출력\n",
    "    # Pipeline 내부의 XGBoost 모델 접근: pipe.named_steps['tree']\n",
    "    if hasattr(pipe.named_steps['tree'], 'feature_importances_'):\n",
    "        feature_imp = pd.DataFrame({\n",
    "            'features': X_train.columns, # X_train이 pandas DataFrame이라고 가정\n",
    "            'values': pipe.named_steps['tree'].feature_importances_\n",
    "        })\n",
    "        feature_imp.sort_values(by='values', ascending=False, inplace=True)\n",
    "        print(\"\\nFeature Importances (Top 10):\")\n",
    "        print(feature_imp.head(10))\n",
    "    else:\n",
    "        print(\"\\nCould not retrieve feature importances.\")\n",
    "\n",
    "    return final_f1_score, pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747f6e0f-ec78-4e02-9ede-7e6d31210e94",
   "metadata": {},
   "source": [
    "# Top 2 Train_Test 및 F1 score 계산 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e454331-8944-4a0a-b10c-1c79226dfb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_top2_binary(X_train, X_test, y_train, y_test, num_classes=6, class_names=None):\n",
    "    \"\"\"\n",
    "    label 0 vs label 1~5 이진 분류 평가:\n",
    "    - predict_proba로 확률 예측\n",
    "    - top1 == 0이면 예측: 0 (label 0)\n",
    "    - top1 != 0이면:\n",
    "        - top2 중 실제 label이 포함되면 예측: 1 (TP)\n",
    "        - 포함되지 않으면 예측: 0 (FN)\n",
    "    \"\"\"\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        (\"sc\", StandardScaler()),\n",
    "        (\"tree\", XGBClassifier(\n",
    "            objective='multi:softprob',\n",
    "            num_class=num_classes,\n",
    "            eval_metric='mlogloss',\n",
    "            random_state=42,\n",
    "            use_label_encoder=False\n",
    "        )),\n",
    "    ])\n",
    "\n",
    "    param_grid = {\n",
    "        'tree__n_estimators': [100, 200, 300],\n",
    "        'tree__max_depth': [3, 5, 7, 10],\n",
    "        'tree__learning_rate': [0.01, 0.1, 0.2],\n",
    "        'tree__subsample': [0.8, 1.0],\n",
    "        'tree__colsample_bytree': [0.8, 1.0],\n",
    "    }\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    grid = GridSearchCV(pipe, param_grid, cv=cv, scoring='f1_macro', n_jobs=-1)\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    print(\"✅ Best Params:\", grid.best_params_)\n",
    "    print(f\"✅ Best CV F1 Macro Score: {grid.best_score_:.3f}\")\n",
    "\n",
    "    best_model = grid.best_estimator_\n",
    "\n",
    "    # 확률 예측\n",
    "    y_proba = best_model.predict_proba(X_test)  # shape: (n_samples, 6)\n",
    "\n",
    "    y_pred_binary = []\n",
    "    y_true_binary = []\n",
    "\n",
    "    for i in range(len(y_test)):\n",
    "        probs = y_proba[i]\n",
    "        top_idx = np.argsort(probs)[::-1]  # 내림차순 정렬된 클래스 인덱스\n",
    "        true_label = y_test.iloc[i]\n",
    "\n",
    "        if top_idx[0] == 0:\n",
    "            pred_label = 0\n",
    "        else:\n",
    "            # top2 중 0 제외하고 확인\n",
    "            top2 = [cls for cls in top_idx if cls != 0][:2]\n",
    "            pred_label = 1 if true_label in top2 else 0\n",
    "\n",
    "        y_pred_binary.append(pred_label)\n",
    "        y_true_binary.append(0 if true_label == 0 else 1)\n",
    "\n",
    "    # F1 Score 계산 (이진 분류)\n",
    "    f1_bin = f1_score(y_true_binary, y_pred_binary)\n",
    "    print(f\"✅ Test F1 Score (Binary: label 0 vs label 1~5): {f1_bin:.3f}\")\n",
    "\n",
    "    # 옵션: classification report\n",
    "    print(\"\\n✅ Binary Classification Report:\")\n",
    "    print(classification_report(y_true_binary, y_pred_binary, target_names=[\"label 0\", \"label 1~5\"]))\n",
    "\n",
    "    # 중요 변수 출력\n",
    "    if hasattr(best_model.named_steps['tree'], 'feature_importances_'):\n",
    "        feature_imp = pd.DataFrame({\n",
    "            'features': X_train.columns,\n",
    "            'values': best_model.named_steps['tree'].feature_importances_\n",
    "        })\n",
    "        feature_imp.sort_values(by='values', ascending=False, inplace=True)\n",
    "        print(\"\\nFeature Importances (Top 10):\")\n",
    "        print(feature_imp.head(10))\n",
    "    else:\n",
    "        print(\"\\nCould not retrieve feature importances.\")\n",
    "\n",
    "    joblib.dump(best_model, 'best_top2_model.joblib')\n",
    "\n",
    "    return f1_bin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ca94e7-9d02-4226-94b9-c701c5e7966e",
   "metadata": {},
   "source": [
    "# Python XGBoost model_uijong_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13adca99-003c-4d33-be4a-9fe1a97286e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "uj_features = pd.read_csv('python_dataset.csv')\n",
    "\n",
    "# 1. PCA를 적용할 피처 컬럼들 선택\n",
    "original_feature_columns = [f'codebert_{i}' for i in range(768)]\n",
    "original_feature_columns = uj_features[original_feature_columns]\n",
    "\n",
    "# 2. 데이터 스케일링\n",
    "X_scaled = StandardScaler().fit_transform(original_feature_columns)\n",
    "\n",
    "# 3. PCA 적용 (40개 주성분)\n",
    "pca_transformer = PCA(n_components=40, random_state=42)\n",
    "X_pca = pca_transformer.fit_transform(X_scaled)\n",
    "\n",
    "# 4. PCA 결과를 새로운 DataFrame으로 생성\n",
    "df_pca_features = pd.DataFrame(\n",
    "    data=X_pca,\n",
    "    columns=[f'PC{i+1}' for i in range(pca_transformer.n_components_)], # 실제 생성된 주성분 개수 사용\n",
    "    index=uj_features.index\n",
    ")\n",
    "\n",
    "merged_df = pd.merge(uj_features.iloc[:, :14], df_pca_features, left_on=uj_features.iloc[:, :14].index, right_on=df_pca_features.index, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f34bb689-e1c3-4b03-a81d-5f444485d4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "uj_features = [\n",
    "    'avg_identifier_length', \n",
    "    'average_function_length', \n",
    "    'token_count',\n",
    "    'function_count', \n",
    "    'blank_ratio', \n",
    "    'identifier_count', \n",
    "    'total_lines',\n",
    "    'comment_ratio', \n",
    "    'max_control_depth',\n",
    "    \"PC1\", \"PC2\", \"PC3\", \"PC4\", \"PC5\", \"PC6\", \"PC7\", \"PC8\", \"PC9\", \"PC10\", \n",
    "    \"PC11\", \"PC12\", \"PC13\", \"PC14\", \"PC15\", \"PC16\", \"PC17\", \"PC18\", \"PC19\", \"PC20\", \n",
    "    \"PC21\", \"PC22\", \"PC23\", \"PC24\", \"PC25\", \"PC26\", \"PC27\", \"PC28\", \"PC29\", \"PC30\", \n",
    "    \"PC31\", \"PC32\", \"PC33\", \"PC34\", \"PC35\", \"PC36\", \"PC37\", \"PC38\", \"PC39\", \"PC40\"\n",
    "]\n",
    "\n",
    "best_xgb_params = {\n",
    "    'tree__colsample_bytree': 1.0,\n",
    "    'tree__learning_rate': 0.1,\n",
    "    'tree__max_depth': 5,\n",
    "    'tree__n_estimators': 300,\n",
    "    'tree__subsample': 0.8\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd697f21-3316-41c6-b2da-d899d598fb14",
   "metadata": {},
   "source": [
    "- 기존 다중 분류 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "4507cbb0-099e-4afb-a1c2-11cf60a5eed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9684\\1639017291.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['multiclass_target_str'] = df[original_label_column_name].astype(str) + '_' + df[model_column_name].astype(str)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9684\\1639017291.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['multiclass_target_encoded'] = encoder.fit_transform(df['multiclass_target_str'])\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [23:47:45] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "생성된 고유 클래스 (문자열): ['1_deepseek' '1_gemini' '1_gpt' '1_grok3' '1_mistral']\n",
      "인코딩된 클래스 수: 5\n",
      "🚀 모델 학습 시작 (최적 파라미터 사용)...\n",
      "✅ 모델 학습 완료!\n",
      "\n",
      "--- 테스트 결과 ---\n",
      "✅ Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.66      0.69        50\n",
      "           1       0.86      0.88      0.87        50\n",
      "           2       0.78      0.76      0.77        50\n",
      "           3       0.80      0.90      0.85        50\n",
      "           4       0.83      0.80      0.82        50\n",
      "\n",
      "    accuracy                           0.80       250\n",
      "   macro avg       0.80      0.80      0.80       250\n",
      "weighted avg       0.80      0.80      0.80       250\n",
      "\n",
      "✅ Test F1 Macro Score: 0.798\n",
      "\n",
      "Feature Importances (Top 10):\n",
      "                   features    values\n",
      "1   average_function_length  0.079111\n",
      "3            function_count  0.059188\n",
      "12                      PC4  0.049886\n",
      "4               blank_ratio  0.043433\n",
      "8         max_control_depth  0.036455\n",
      "11                      PC3  0.035751\n",
      "33                     PC25  0.030099\n",
      "16                      PC8  0.029444\n",
      "10                      PC2  0.027960\n",
      "22                     PC14  0.026447\n",
      "\n",
      "최종 반환된 Test F1 Macro Score: 0.780\n"
     ]
    }
   ],
   "source": [
    "# 모델 개수 기준으로만 train_test_split 후 성능 평가\n",
    "X_train, X_test, y_train, y_test, class_names = extraction_multiclass_version1(merged_df, uj_features, 'model', 'label')\n",
    "num_classes = len(class_names)\n",
    "\n",
    "inal_f1, trained_model = train_and_evaluate_with_best_params(X_train, X_test, y_train, y_test, num_classes, best_xgb_params)\n",
    "\n",
    "print(f\"\\n최종 반환된 Test F1 Macro Score: {final_f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ccb666f1-e6f2-4a5a-a342-04b408746d91",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "extraction_multiclass_version2() missing 1 required positional argument: 'group_col'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 문제 개수 기준으로 train_test_split 후 성능 평가\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m X_train, X_test, y_train, y_test, encoder, class_names \u001b[38;5;241m=\u001b[39m extraction_multiclass_version2(merged_df, uj_features, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(class_names)\n\u001b[0;32m      6\u001b[0m final_f1, trained_model \u001b[38;5;241m=\u001b[39m train_and_evaluate_with_best_params(X_train, X_test, y_train, y_test, num_classes, best_xgb_params)\n",
      "\u001b[1;31mTypeError\u001b[0m: extraction_multiclass_version2() missing 1 required positional argument: 'group_col'"
     ]
    }
   ],
   "source": [
    "# 문제 개수 기준으로 train_test_split 후 성능 평가\n",
    "\n",
    "X_train, X_test, y_train, y_test, encoder, class_names = extraction_multiclass_version2(merged_df, uj_features, 'model', 'label', 'problem_id')\n",
    "num_classes = len(class_names)\n",
    "\n",
    "final_f1, trained_model = train_and_evaluate_with_best_params(X_train, X_test, y_train, y_test, num_classes, best_xgb_params)\n",
    "\n",
    "print(f\"\\n최종 반환된 Test F1 Macro Score: {final_f1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef05dd29-97d1-460f-9d1d-b58bea820b1a",
   "metadata": {},
   "source": [
    "- top 2 다중 분류 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60ec2921-e537-4fc0-9e24-7f3029bcd864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "생성된 고유 클래스 (문자열): ['0_Human' '1_deepseek' '1_gemini' '1_gpt' '1_grok3' '1_mistral']\n",
      "인코딩된 클래스 수: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\numpy\\ma\\core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:48:02] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best Params: {'tree__colsample_bytree': 1.0, 'tree__learning_rate': 0.1, 'tree__max_depth': 5, 'tree__n_estimators': 300, 'tree__subsample': 0.8}\n",
      "✅ Best CV F1 Macro Score: 0.723\n",
      "✅ Test F1 Score (Binary: label 0 vs label 1~5): 0.874\n",
      "\n",
      "✅ Binary Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     label 0       0.82      1.00      0.90       250\n",
      "   label 1~5       1.00      0.78      0.87       250\n",
      "\n",
      "    accuracy                           0.89       500\n",
      "   macro avg       0.91      0.89      0.89       500\n",
      "weighted avg       0.91      0.89      0.89       500\n",
      "\n",
      "\n",
      "Feature Importances (Top 10):\n",
      "                   features    values\n",
      "0     avg_identifier_length  0.091104\n",
      "3            function_count  0.071894\n",
      "1   average_function_length  0.060096\n",
      "12                      PC4  0.047806\n",
      "4               blank_ratio  0.034466\n",
      "10                      PC2  0.034401\n",
      "11                      PC3  0.026204\n",
      "20                     PC12  0.024774\n",
      "18                     PC10  0.024624\n",
      "5          identifier_count  0.023955\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8738738738738738"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, class_names = extraction_multiclass_version1(merged_df, uj_features, 'model', 'label')\n",
    "\n",
    "train_test_top2_binary(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "00c87a4e-6d28-40ca-86fe-eef2cad55f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:56:45] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best Params: {'tree__colsample_bytree': 1.0, 'tree__learning_rate': 0.1, 'tree__max_depth': 5, 'tree__n_estimators': 300, 'tree__subsample': 0.8}\n",
      "✅ Best CV F1 Macro Score: 0.706\n",
      "✅ Test F1 Score (Binary: label 0 vs label 1~5): 0.881\n",
      "\n",
      "✅ Binary Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     label 0       0.83      1.00      0.90       250\n",
      "   label 1~5       1.00      0.79      0.88       250\n",
      "\n",
      "    accuracy                           0.89       500\n",
      "   macro avg       0.91      0.89      0.89       500\n",
      "weighted avg       0.91      0.89      0.89       500\n",
      "\n",
      "\n",
      "Feature Importances (Top 10):\n",
      "                   features    values\n",
      "0     avg_identifier_length  0.090983\n",
      "1   average_function_length  0.063929\n",
      "3            function_count  0.059669\n",
      "12                      PC4  0.044067\n",
      "10                      PC2  0.035989\n",
      "4               blank_ratio  0.034587\n",
      "22                     PC14  0.026684\n",
      "18                     PC10  0.025531\n",
      "6               total_lines  0.025265\n",
      "5          identifier_count  0.025109\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8814317673378076"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, encoder, class_names = extraction_multiclass_version2(merged_df, uj_features, 'model', 'label', 'problem_id')\n",
    "\n",
    "train_test_top2_binary(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016260dd-2697-4f8d-8e44-8c2c85bafed9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Python XGBoost model_yechan_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "39c42334-ce45-4300-94f9-f3825e27153b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submission_id</th>\n",
       "      <th>problem_id</th>\n",
       "      <th>total_lines</th>\n",
       "      <th>blank_ratio</th>\n",
       "      <th>comment_ratio</th>\n",
       "      <th>function_count</th>\n",
       "      <th>function_length</th>\n",
       "      <th>conditional_depth</th>\n",
       "      <th>conditional_count</th>\n",
       "      <th>identifier_count</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_758</th>\n",
       "      <th>feature_759</th>\n",
       "      <th>feature_760</th>\n",
       "      <th>feature_761</th>\n",
       "      <th>feature_762</th>\n",
       "      <th>feature_763</th>\n",
       "      <th>feature_764</th>\n",
       "      <th>feature_765</th>\n",
       "      <th>feature_766</th>\n",
       "      <th>feature_767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p00154_deepseek.py</td>\n",
       "      <td>p00154</td>\n",
       "      <td>41</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.024</td>\n",
       "      <td>1</td>\n",
       "      <td>37.0</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>0.451099</td>\n",
       "      <td>0.796144</td>\n",
       "      <td>-0.061147</td>\n",
       "      <td>-0.406667</td>\n",
       "      <td>0.646011</td>\n",
       "      <td>-0.459290</td>\n",
       "      <td>0.382395</td>\n",
       "      <td>-0.000334</td>\n",
       "      <td>-0.093416</td>\n",
       "      <td>0.200387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p00154_gemini.py</td>\n",
       "      <td>p00154</td>\n",
       "      <td>45</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>31.5</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>0.438789</td>\n",
       "      <td>0.790439</td>\n",
       "      <td>-0.069774</td>\n",
       "      <td>-0.363625</td>\n",
       "      <td>0.643189</td>\n",
       "      <td>-0.510428</td>\n",
       "      <td>0.426587</td>\n",
       "      <td>-0.027792</td>\n",
       "      <td>-0.081435</td>\n",
       "      <td>0.217165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p00154_gpt.py</td>\n",
       "      <td>p00154</td>\n",
       "      <td>46</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.196</td>\n",
       "      <td>1</td>\n",
       "      <td>43.0</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>0.460480</td>\n",
       "      <td>0.796184</td>\n",
       "      <td>-0.047687</td>\n",
       "      <td>-0.414757</td>\n",
       "      <td>0.639285</td>\n",
       "      <td>-0.470537</td>\n",
       "      <td>0.402502</td>\n",
       "      <td>-0.010223</td>\n",
       "      <td>-0.078263</td>\n",
       "      <td>0.176439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p00154_grok3.py</td>\n",
       "      <td>p00154</td>\n",
       "      <td>35</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>0.458559</td>\n",
       "      <td>0.783600</td>\n",
       "      <td>-0.043114</td>\n",
       "      <td>-0.370587</td>\n",
       "      <td>0.650745</td>\n",
       "      <td>-0.506219</td>\n",
       "      <td>0.399987</td>\n",
       "      <td>0.001227</td>\n",
       "      <td>-0.114320</td>\n",
       "      <td>0.194047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p00154_mistral.py</td>\n",
       "      <td>p00154</td>\n",
       "      <td>41</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>0.461104</td>\n",
       "      <td>0.791975</td>\n",
       "      <td>-0.033994</td>\n",
       "      <td>-0.391882</td>\n",
       "      <td>0.649641</td>\n",
       "      <td>-0.475753</td>\n",
       "      <td>0.399520</td>\n",
       "      <td>-0.018063</td>\n",
       "      <td>-0.104741</td>\n",
       "      <td>0.214613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 781 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        submission_id problem_id  total_lines  blank_ratio  comment_ratio  \\\n",
       "0  p00154_deepseek.py     p00154           41        0.098          0.024   \n",
       "1    p00154_gemini.py     p00154           45        0.222          0.000   \n",
       "2       p00154_gpt.py     p00154           46        0.022          0.196   \n",
       "3     p00154_grok3.py     p00154           35        0.114          0.000   \n",
       "4   p00154_mistral.py     p00154           41        0.098          0.000   \n",
       "\n",
       "   function_count  function_length  conditional_depth  conditional_count  \\\n",
       "0               1             37.0                  6                 11   \n",
       "1               2             31.5                  4                 10   \n",
       "2               1             43.0                  4                  9   \n",
       "3               0              0.0                  6                 10   \n",
       "4               2             17.0                  4                  9   \n",
       "\n",
       "   identifier_count  ...  feature_758  feature_759 feature_760  feature_761  \\\n",
       "0                23  ...     0.451099     0.796144   -0.061147    -0.406667   \n",
       "1                22  ...     0.438789     0.790439   -0.069774    -0.363625   \n",
       "2                29  ...     0.460480     0.796184   -0.047687    -0.414757   \n",
       "3                22  ...     0.458559     0.783600   -0.043114    -0.370587   \n",
       "4                23  ...     0.461104     0.791975   -0.033994    -0.391882   \n",
       "\n",
       "   feature_762  feature_763  feature_764  feature_765  feature_766  \\\n",
       "0     0.646011    -0.459290     0.382395    -0.000334    -0.093416   \n",
       "1     0.643189    -0.510428     0.426587    -0.027792    -0.081435   \n",
       "2     0.639285    -0.470537     0.402502    -0.010223    -0.078263   \n",
       "3     0.650745    -0.506219     0.399987     0.001227    -0.114320   \n",
       "4     0.649641    -0.475753     0.399520    -0.018063    -0.104741   \n",
       "\n",
       "   feature_767  \n",
       "0     0.200387  \n",
       "1     0.217165  \n",
       "2     0.176439  \n",
       "3     0.194047  \n",
       "4     0.214613  \n",
       "\n",
       "[5 rows x 781 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yc_features = pd.read_csv('python_features.csv')\n",
    "yc_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a755b4be-cdcd-442e-b135-9751b2181a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "yc_features = [\n",
    "    'total_lines', \n",
    "    'blank_ratio',\n",
    "    'comment_ratio', \n",
    "    'function_count', \n",
    "    'function_length',\n",
    "    'conditional_depth', \n",
    "    'conditional_count', \n",
    "    'identifier_count',\n",
    "    'token_count', \n",
    "    \"PC1\", \"PC2\", \"PC3\", \"PC4\", \"PC5\", \"PC6\", \"PC7\", \"PC8\", \"PC9\", \"PC10\", \n",
    "    \"PC11\", \"PC12\", \"PC13\", \"PC14\", \"PC15\", \"PC16\", \"PC17\", \"PC18\", \"PC19\", \"PC20\", \n",
    "    \"PC21\", \"PC22\", \"PC23\", \"PC24\", \"PC25\", \"PC26\", \"PC27\", \"PC28\", \"PC29\", \"PC30\", \n",
    "    \"PC31\", \"PC32\", \"PC33\", \"PC34\", \"PC35\", \"PC36\", \"PC37\", \"PC38\", \"PC39\", \"PC40\"\n",
    "]\n",
    "\n",
    "best_xgb_params = {\n",
    "    'tree__colsample_bytree': 0.8,\n",
    "    'tree__learning_rate': 0.2,\n",
    "    'tree__max_depth': 3,\n",
    "    'tree__n_estimators': 300,\n",
    "    'tree__subsample': 0.8\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6acf6e5b-cc77-4862-a33f-3f2de4e28a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "yc_features = pd.read_csv('python_features.csv')\n",
    "\n",
    "# 1. PCA를 적용할 피처 컬럼들 선택\n",
    "original_feature_columns = [f'feature_{i}' for i in range(768)]\n",
    "original_feature_columns = yc_features[original_feature_columns]\n",
    "\n",
    "# 2. 데이터 스케일링\n",
    "X_scaled = StandardScaler().fit_transform(original_feature_columns)\n",
    "\n",
    "# 3. PCA 적용 (40개 주성분)\n",
    "pca_transformer = PCA(n_components=40, random_state=42)\n",
    "X_pca = pca_transformer.fit_transform(X_scaled)\n",
    "\n",
    "# 4. PCA 결과를 새로운 DataFrame으로 생성\n",
    "df_pca_features = pd.DataFrame(\n",
    "    data=X_pca,\n",
    "    columns=[f'PC{i+1}' for i in range(pca_transformer.n_components_)], # 실제 생성된 주성분 개수 사용\n",
    "    index=yc_features.index\n",
    ")\n",
    "\n",
    "merged_df = pd.merge(yc_features.iloc[:, :14], df_pca_features, left_on=yc_features.iloc[:, :13].index, right_on=df_pca_features.index, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "439d68f6-21ac-49ae-a170-d80578fb6c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "생성된 고유 클래스 (문자열): ['0_human' '1_deepseek' '1_gemini' '1_gpt' '1_grok3' '1_mistral']\n",
      "인코딩된 클래스 수: 6\n",
      "🚀 모델 학습 시작 (최적 파라미터 사용)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:43:43] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 모델 학습 완료!\n",
      "\n",
      "--- 테스트 결과 ---\n",
      "✅ Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.91       249\n",
      "           1       0.76      0.56      0.64        50\n",
      "           2       0.83      0.76      0.79        50\n",
      "           3       0.72      0.82      0.77        50\n",
      "           4       0.73      0.44      0.55        50\n",
      "           5       0.77      0.74      0.76        50\n",
      "\n",
      "    accuracy                           0.82       499\n",
      "   macro avg       0.78      0.71      0.74       499\n",
      "weighted avg       0.81      0.82      0.81       499\n",
      "\n",
      "✅ Test F1 Macro Score: 0.736\n",
      "\n",
      "Feature Importances (Top 10):\n",
      "             features    values\n",
      "4     function_length  0.079352\n",
      "2       comment_ratio  0.073692\n",
      "3      function_count  0.058480\n",
      "10                PC2  0.042473\n",
      "24               PC16  0.035735\n",
      "1         blank_ratio  0.032987\n",
      "18               PC10  0.030515\n",
      "5   conditional_depth  0.027405\n",
      "12                PC4  0.026977\n",
      "11                PC3  0.025151\n",
      "\n",
      "최종 반환된 Test F1 Macro Score: 0.759\n"
     ]
    }
   ],
   "source": [
    "# 모델 개수 기준으로만 train_test_split 후 성능 평가\n",
    "X_train, X_test, y_train, y_test, class_names = extraction_multiclass_version1(merged_df, yc_features, 'model', 'label')\n",
    "num_classes = len(class_names)\n",
    "\n",
    "inal_f1, trained_model = train_and_evaluate_with_best_params(X_train, X_test, y_train, y_test, num_classes, best_xgb_params)\n",
    "\n",
    "print(f\"\\n최종 반환된 Test F1 Macro Score: {final_f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "62afac87-1dad-4607-a3a8-7e67c1006ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 모델 학습 시작 (최적 파라미터 사용)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:44:07] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 모델 학습 완료!\n",
      "\n",
      "--- 테스트 결과 ---\n",
      "✅ Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.60      0.69        50\n",
      "           1       0.84      0.84      0.84        50\n",
      "           2       0.89      0.80      0.84        50\n",
      "           3       0.76      0.58      0.66        50\n",
      "           4       0.84      0.95      0.89       249\n",
      "           5       0.83      0.80      0.82        50\n",
      "\n",
      "    accuracy                           0.84       499\n",
      "   macro avg       0.83      0.76      0.79       499\n",
      "weighted avg       0.83      0.84      0.83       499\n",
      "\n",
      "✅ Test F1 Macro Score: 0.790\n",
      "\n",
      "Feature Importances (Top 10):\n",
      "           features    values\n",
      "4   function_length  0.088338\n",
      "2     comment_ratio  0.076148\n",
      "10              PC2  0.045436\n",
      "3    function_count  0.037556\n",
      "1       blank_ratio  0.034610\n",
      "12              PC4  0.032249\n",
      "24             PC16  0.032048\n",
      "18             PC10  0.030753\n",
      "11              PC3  0.026638\n",
      "17              PC9  0.025908\n",
      "\n",
      "최종 반환된 Test F1 Macro Score: 0.790\n"
     ]
    }
   ],
   "source": [
    "# 문제 개수 기준으로 train_test_split 후 성능 평가\n",
    "\n",
    "X_train, X_test, y_train, y_test, encoder, class_names = extraction_multiclass_version2(merged_df, yc_features, 'model', 'label', 'problem_id')\n",
    "num_classes = len(class_names)\n",
    "\n",
    "final_f1, trained_model = train_and_evaluate_with_best_params(X_train, X_test, y_train, y_test, num_classes, best_xgb_params)\n",
    "\n",
    "print(f\"\\n최종 반환된 Test F1 Macro Score: {final_f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba2d796-27aa-4bfd-acce-aee1408c1dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, class_names = extraction_multiclass_version1(merged_df, yc_features, 'model', 'label')\n",
    "\n",
    "train_test_top2_binary(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89aaa948-08fe-413f-a47f-95b4d4d40ab2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# C++ XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "824e208a-dca2-45fe-85c6-23b2ae40ff37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_0</th>\n",
       "      <th>problem_id</th>\n",
       "      <th>language</th>\n",
       "      <th>code_size</th>\n",
       "      <th>label</th>\n",
       "      <th>model</th>\n",
       "      <th>total_lines</th>\n",
       "      <th>blank_ratio</th>\n",
       "      <th>comment_ratio</th>\n",
       "      <th>num_funcs</th>\n",
       "      <th>...</th>\n",
       "      <th>PC31</th>\n",
       "      <th>PC32</th>\n",
       "      <th>PC33</th>\n",
       "      <th>PC34</th>\n",
       "      <th>PC35</th>\n",
       "      <th>PC36</th>\n",
       "      <th>PC37</th>\n",
       "      <th>PC38</th>\n",
       "      <th>PC39</th>\n",
       "      <th>PC40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>p01337</td>\n",
       "      <td>C++</td>\n",
       "      <td>1114</td>\n",
       "      <td>0</td>\n",
       "      <td>Human</td>\n",
       "      <td>46</td>\n",
       "      <td>0.0870</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.325554</td>\n",
       "      <td>1.557931</td>\n",
       "      <td>3.063398</td>\n",
       "      <td>0.454610</td>\n",
       "      <td>3.263335</td>\n",
       "      <td>0.626589</td>\n",
       "      <td>-1.530042</td>\n",
       "      <td>1.127741</td>\n",
       "      <td>-2.004430</td>\n",
       "      <td>1.328907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>p01337</td>\n",
       "      <td>C++</td>\n",
       "      <td>2833</td>\n",
       "      <td>0</td>\n",
       "      <td>Human</td>\n",
       "      <td>97</td>\n",
       "      <td>0.0619</td>\n",
       "      <td>0.1959</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.846850</td>\n",
       "      <td>-0.477210</td>\n",
       "      <td>2.198550</td>\n",
       "      <td>1.871701</td>\n",
       "      <td>-1.557638</td>\n",
       "      <td>-0.111932</td>\n",
       "      <td>0.069547</td>\n",
       "      <td>-1.200308</td>\n",
       "      <td>0.149679</td>\n",
       "      <td>-0.826967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>p01337</td>\n",
       "      <td>C++</td>\n",
       "      <td>979</td>\n",
       "      <td>0</td>\n",
       "      <td>Human</td>\n",
       "      <td>45</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2.005994</td>\n",
       "      <td>2.557708</td>\n",
       "      <td>-1.857111</td>\n",
       "      <td>-1.744686</td>\n",
       "      <td>1.165328</td>\n",
       "      <td>0.416467</td>\n",
       "      <td>0.170424</td>\n",
       "      <td>-1.362009</td>\n",
       "      <td>-0.478823</td>\n",
       "      <td>1.733742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>p01337</td>\n",
       "      <td>C++</td>\n",
       "      <td>1312</td>\n",
       "      <td>0</td>\n",
       "      <td>Human</td>\n",
       "      <td>64</td>\n",
       "      <td>0.1406</td>\n",
       "      <td>0.0312</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4.727966</td>\n",
       "      <td>0.493742</td>\n",
       "      <td>-0.624430</td>\n",
       "      <td>-2.398730</td>\n",
       "      <td>-0.645845</td>\n",
       "      <td>-0.426422</td>\n",
       "      <td>-1.469715</td>\n",
       "      <td>-0.862431</td>\n",
       "      <td>-2.669949</td>\n",
       "      <td>0.540521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>p01337</td>\n",
       "      <td>C++</td>\n",
       "      <td>976</td>\n",
       "      <td>0</td>\n",
       "      <td>Human</td>\n",
       "      <td>55</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.075705</td>\n",
       "      <td>4.047883</td>\n",
       "      <td>-1.758351</td>\n",
       "      <td>-1.254380</td>\n",
       "      <td>3.423956</td>\n",
       "      <td>3.251735</td>\n",
       "      <td>-0.057412</td>\n",
       "      <td>-0.012487</td>\n",
       "      <td>-3.018549</td>\n",
       "      <td>2.550404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>2495</td>\n",
       "      <td>p00864</td>\n",
       "      <td>C++</td>\n",
       "      <td>1260</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt</td>\n",
       "      <td>45</td>\n",
       "      <td>0.1778</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.323250</td>\n",
       "      <td>0.548850</td>\n",
       "      <td>0.444057</td>\n",
       "      <td>-1.280167</td>\n",
       "      <td>-2.323654</td>\n",
       "      <td>0.612248</td>\n",
       "      <td>-0.214173</td>\n",
       "      <td>-2.401699</td>\n",
       "      <td>-0.430318</td>\n",
       "      <td>1.267709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>2496</td>\n",
       "      <td>p00864</td>\n",
       "      <td>C++</td>\n",
       "      <td>1159</td>\n",
       "      <td>1</td>\n",
       "      <td>grok3</td>\n",
       "      <td>46</td>\n",
       "      <td>0.1957</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.155004</td>\n",
       "      <td>-0.921301</td>\n",
       "      <td>-1.920931</td>\n",
       "      <td>-0.066455</td>\n",
       "      <td>-1.949138</td>\n",
       "      <td>-0.441582</td>\n",
       "      <td>-0.242712</td>\n",
       "      <td>-1.577245</td>\n",
       "      <td>-0.106367</td>\n",
       "      <td>1.881415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>2497</td>\n",
       "      <td>p00864</td>\n",
       "      <td>C++</td>\n",
       "      <td>915</td>\n",
       "      <td>1</td>\n",
       "      <td>gemini</td>\n",
       "      <td>39</td>\n",
       "      <td>0.1538</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.434307</td>\n",
       "      <td>0.348766</td>\n",
       "      <td>1.584241</td>\n",
       "      <td>0.556959</td>\n",
       "      <td>-3.253664</td>\n",
       "      <td>0.549322</td>\n",
       "      <td>-0.172137</td>\n",
       "      <td>-0.512983</td>\n",
       "      <td>0.878498</td>\n",
       "      <td>1.432289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>2498</td>\n",
       "      <td>p00864</td>\n",
       "      <td>C++</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>deepseek</td>\n",
       "      <td>38</td>\n",
       "      <td>0.1842</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.594091</td>\n",
       "      <td>-0.899043</td>\n",
       "      <td>0.458897</td>\n",
       "      <td>-0.659031</td>\n",
       "      <td>-2.919256</td>\n",
       "      <td>1.291221</td>\n",
       "      <td>0.039594</td>\n",
       "      <td>-0.715527</td>\n",
       "      <td>0.294640</td>\n",
       "      <td>2.425636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>2499</td>\n",
       "      <td>p00864</td>\n",
       "      <td>C++</td>\n",
       "      <td>1076</td>\n",
       "      <td>1</td>\n",
       "      <td>mistral</td>\n",
       "      <td>39</td>\n",
       "      <td>0.1795</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.365750</td>\n",
       "      <td>1.460770</td>\n",
       "      <td>-0.652119</td>\n",
       "      <td>-0.284813</td>\n",
       "      <td>-2.390622</td>\n",
       "      <td>2.880213</td>\n",
       "      <td>-2.608691</td>\n",
       "      <td>-0.537977</td>\n",
       "      <td>-0.719586</td>\n",
       "      <td>2.115335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      key_0 problem_id language  code_size  label     model  total_lines  \\\n",
       "0         0     p01337      C++       1114      0     Human           46   \n",
       "1         1     p01337      C++       2833      0     Human           97   \n",
       "2         2     p01337      C++        979      0     Human           45   \n",
       "3         3     p01337      C++       1312      0     Human           64   \n",
       "4         4     p01337      C++        976      0     Human           55   \n",
       "...     ...        ...      ...        ...    ...       ...          ...   \n",
       "2495   2495     p00864      C++       1260      1       gpt           45   \n",
       "2496   2496     p00864      C++       1159      1     grok3           46   \n",
       "2497   2497     p00864      C++        915      1    gemini           39   \n",
       "2498   2498     p00864      C++       1000      1  deepseek           38   \n",
       "2499   2499     p00864      C++       1076      1   mistral           39   \n",
       "\n",
       "      blank_ratio  comment_ratio  num_funcs  ...      PC31      PC32  \\\n",
       "0          0.0870         0.0000          2  ...  0.325554  1.557931   \n",
       "1          0.0619         0.1959          4  ...  1.846850 -0.477210   \n",
       "2          0.0667         0.0000          3  ...  2.005994  2.557708   \n",
       "3          0.1406         0.0312          4  ...  4.727966  0.493742   \n",
       "4          0.0000         0.0000          4  ... -2.075705  4.047883   \n",
       "...           ...            ...        ...  ...       ...       ...   \n",
       "2495       0.1778         0.0000          1  ...  2.323250  0.548850   \n",
       "2496       0.1957         0.0000          1  ... -0.155004 -0.921301   \n",
       "2497       0.1538         0.0000          1  ... -0.434307  0.348766   \n",
       "2498       0.1842         0.0000          1  ... -0.594091 -0.899043   \n",
       "2499       0.1795         0.0000          2  ...  2.365750  1.460770   \n",
       "\n",
       "          PC33      PC34      PC35      PC36      PC37      PC38      PC39  \\\n",
       "0     3.063398  0.454610  3.263335  0.626589 -1.530042  1.127741 -2.004430   \n",
       "1     2.198550  1.871701 -1.557638 -0.111932  0.069547 -1.200308  0.149679   \n",
       "2    -1.857111 -1.744686  1.165328  0.416467  0.170424 -1.362009 -0.478823   \n",
       "3    -0.624430 -2.398730 -0.645845 -0.426422 -1.469715 -0.862431 -2.669949   \n",
       "4    -1.758351 -1.254380  3.423956  3.251735 -0.057412 -0.012487 -3.018549   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2495  0.444057 -1.280167 -2.323654  0.612248 -0.214173 -2.401699 -0.430318   \n",
       "2496 -1.920931 -0.066455 -1.949138 -0.441582 -0.242712 -1.577245 -0.106367   \n",
       "2497  1.584241  0.556959 -3.253664  0.549322 -0.172137 -0.512983  0.878498   \n",
       "2498  0.458897 -0.659031 -2.919256  1.291221  0.039594 -0.715527  0.294640   \n",
       "2499 -0.652119 -0.284813 -2.390622  2.880213 -2.608691 -0.537977 -0.719586   \n",
       "\n",
       "          PC40  \n",
       "0     1.328907  \n",
       "1    -0.826967  \n",
       "2     1.733742  \n",
       "3     0.540521  \n",
       "4     2.550404  \n",
       "...        ...  \n",
       "2495  1.267709  \n",
       "2496  1.881415  \n",
       "2497  1.432289  \n",
       "2498  2.425636  \n",
       "2499  2.115335  \n",
       "\n",
       "[2500 rows x 55 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpp_features = pd.read_csv('cpp_dataset_with_cobert_and_ai_adjusted.csv')\n",
    "main_features = cpp_features.iloc[:, :14]\n",
    "\n",
    "# 1. PCA를 적용할 피처 컬럼들 선택 (정확히 768개라고 가정)\n",
    "original_feature_columns = [f'vec_{i}' for i in range(768)]\n",
    "original_feature_columns = cpp_features[original_feature_columns]\n",
    "\n",
    "# 2. 데이터 스케일링\n",
    "X_scaled = StandardScaler().fit_transform(original_feature_columns)\n",
    "\n",
    "# 3. PCA 적용\n",
    "pca_transformer = PCA(n_components=40, random_state=42)\n",
    "X_pca = pca_transformer.fit_transform(X_scaled)\n",
    "\n",
    "# 4. PCA 결과를 새로운 DataFrame으로 생성\n",
    "df_pca_features = pd.DataFrame(\n",
    "    data=X_pca,\n",
    "    columns=[f'PC{i+1}' for i in range(pca_transformer.n_components_)], # 실제 생성된 주성분 개수 사용\n",
    "    index=cpp_features.index\n",
    ")\n",
    "\n",
    "merged_df = pd.merge(main_features, df_pca_features, left_on=main_features.index, right_on=df_pca_features.index, how='inner')\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "17277037-fcae-4753-87bc-3c379027bc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "jw_features = ['code_size', \n",
    "                'total_lines', \n",
    "                'blank_ratio', \n",
    "                'comment_ratio', \n",
    "                'num_funcs', \n",
    "                'avg_func_length', \n",
    "                'max_control_depth', \n",
    "                'control_count', \n",
    "                'unique_identifiers',\n",
    "                'token_count', \n",
    "                \"PC1\", \"PC2\", \"PC3\", \"PC4\", \"PC5\", \"PC6\", \"PC7\", \"PC8\", \"PC9\", \"PC10\", \n",
    "                \"PC11\", \"PC12\", \"PC13\", \"PC14\", \"PC15\", \"PC16\", \"PC17\", \"PC18\", \"PC19\", \"PC20\", \n",
    "                \"PC21\", \"PC22\", \"PC23\", \"PC24\", \"PC25\", \"PC26\", \"PC27\", \"PC28\", \"PC29\", \"PC30\", \n",
    "                \"PC31\", \"PC32\", \"PC33\", \"PC34\", \"PC35\", \"PC36\", \"PC37\", \"PC38\", \"PC39\", \"PC40\", \n",
    "                # \"PC41\", \"PC42\", \"PC43\", \"PC44\", \"PC45\", \"PC46\", \"PC47\", \"PC48\", \"PC49\", \"PC50\", \n",
    "                # \"PC51\", \"PC52\", \"PC53\", \"PC54\", \"PC55\", \"PC56\", \"PC57\", \"PC58\", \"PC59\", \"PC60\", \n",
    "               ]\n",
    "\n",
    "best_xgb_params = {\n",
    "    'tree__colsample_bytree': 1.0,\n",
    "    'tree__learning_rate': 0.1,\n",
    "    'tree__max_depth': 3,\n",
    "    'tree__n_estimators': 300,\n",
    "    'tree__subsample': 0.8\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "1586bbba-e4f7-406b-beab-cb9f77da7865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "생성된 고유 클래스 (문자열): ['0_Human' '1_deepseek' '1_gemini' '1_gpt' '1_grok3' '1_mistral']\n",
      "인코딩된 클래스 수: 6\n",
      "🚀 모델 학습 시작 (최적 파라미터 사용)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:51:00] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 모델 학습 완료!\n",
      "\n",
      "--- 테스트 결과 ---\n",
      "✅ Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93       250\n",
      "           1       0.52      0.56      0.54        50\n",
      "           2       0.80      0.70      0.74        50\n",
      "           3       0.84      0.76      0.80        50\n",
      "           4       0.79      0.76      0.78        50\n",
      "           5       0.56      0.62      0.59        50\n",
      "\n",
      "    accuracy                           0.81       500\n",
      "   macro avg       0.74      0.72      0.73       500\n",
      "weighted avg       0.81      0.81      0.81       500\n",
      "\n",
      "✅ Test F1 Macro Score: 0.730\n",
      "\n",
      "Feature Importances (Top 10):\n",
      "           features    values\n",
      "10              PC1  0.100611\n",
      "3     comment_ratio  0.079878\n",
      "2       blank_ratio  0.036052\n",
      "18              PC9  0.035420\n",
      "13              PC4  0.031089\n",
      "11              PC2  0.030910\n",
      "5   avg_func_length  0.028372\n",
      "24             PC15  0.027449\n",
      "17              PC8  0.025208\n",
      "0         code_size  0.024968\n",
      "\n",
      "최종 반환된 Test F1 Macro Score: 0.790\n"
     ]
    }
   ],
   "source": [
    "# 모델 개수 기준으로만 train_test_split 후 성능 평가\n",
    "X_train, X_test, y_train, y_test, class_names = extraction_multiclass_version1(merged_df, jw_features, 'model', 'label')\n",
    "num_classes = len(class_names)\n",
    "\n",
    "inal_f1, trained_model = train_and_evaluate_with_best_params(X_train, X_test, y_train, y_test, num_classes, best_xgb_params)\n",
    "\n",
    "print(f\"\\n최종 반환된 Test F1 Macro Score: {final_f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "4c42614f-3b95-49d4-b3e8-055f07197f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 모델 학습 시작 (최적 파라미터 사용)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:51:27] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 모델 학습 완료!\n",
      "\n",
      "--- 테스트 결과 ---\n",
      "✅ Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96       250\n",
      "           1       0.58      0.56      0.57        50\n",
      "           2       0.85      0.68      0.76        50\n",
      "           3       0.90      0.88      0.89        50\n",
      "           4       0.88      0.76      0.82        50\n",
      "           5       0.61      0.78      0.68        50\n",
      "\n",
      "    accuracy                           0.85       500\n",
      "   macro avg       0.80      0.77      0.78       500\n",
      "weighted avg       0.86      0.85      0.85       500\n",
      "\n",
      "✅ Test F1 Macro Score: 0.780\n",
      "\n",
      "Feature Importances (Top 10):\n",
      "             features    values\n",
      "10                PC1  0.096773\n",
      "3       comment_ratio  0.080674\n",
      "2         blank_ratio  0.036473\n",
      "11                PC2  0.034372\n",
      "18                PC9  0.032440\n",
      "15                PC6  0.029352\n",
      "13                PC4  0.028222\n",
      "17                PC8  0.027027\n",
      "5     avg_func_length  0.025284\n",
      "6   max_control_depth  0.024944\n",
      "\n",
      "최종 반환된 Test F1 Macro Score: 0.780\n"
     ]
    }
   ],
   "source": [
    "# 문제 개수 기준으로 train_test_split 후 성능 평가\n",
    "\n",
    "X_train, X_test, y_train, y_test, encoder, class_names = extraction_multiclass_version2(merged_df, jw_features, 'model', 'label', 'problem_id')\n",
    "num_classes = len(class_names)\n",
    "\n",
    "final_f1, trained_model = train_and_evaluate_with_best_params(X_train, X_test, y_train, y_test, num_classes, best_xgb_params)\n",
    "\n",
    "print(f\"\\n최종 반환된 Test F1 Macro Score: {final_f1:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
